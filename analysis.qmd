# Statistical analysis & data visualizations {#sec-analysis}

## Statistical analysis

R was created as a statistics-focused programming language, so it's important to at least briefly showcase how R can be used to run statistical methods and quickly produce results that can then be visualized, used in reports, and stored for future use.  However, institutional researchers come from many different backgrounds, and we don't want to assume that all IR professionals reading this guide have the same level of knowledge of statistical methods.  We'll keep this section brief, but know that if a method exists, it likely has an implementation in R.

In this section we'll build off of the occupational projections data that we worked with in @sec-dataset2, which is stored as the R data object `projections_data`.

{{< include cleanoccupationsdata.qmd >}}

### Descriptive statistics

During data cleaning, we utilized the `summary()` function in conjunction with `glimpse()` to quickly examine a dataset.  The `summary()` function displays basic descriptive statistics about every numeric variable in the dataset:

```{R}
summary(projections_data)
```

Here we can quickly identify some important information about the dataset:

* it includes `r count(projections_data)` occupations that currently employ a range of `r min(projections_data$Current_jobs)` to `r prettyNum(max(projections_data$Current_jobs), big.mark = ",")` persons,^[Though the summary occupation lines likely cover persons in all occupations, it seems an occupation has to have 100 or more workers to be included at a detail level in these reports.]
* the typical occupation is projected to grow `r scales::label_percent()(median(projections_data$Change_pct))` over the next ten years,
* the median occupation will have `r median(projections_data$Tot_openings)` opening each year,^[from growth ~`r median(projections_data$Growth)`/yr, exits ~`r median(projections_data$Exits)`/yr, and transfers ~`r median(projections_data$Transfers)`/yr.  Exits are people in the occupation leaving the labor force (mainly retirements), while transfers are people moving into a different occupation.] and
* the median occupation pays `r scales::label_dollar()(median(projections_data$annual_wage, na.rm=TRUE))`.

### Inferential statistics: linear regression

Now let's use linear regression to build a simple model.  Let's see whether annual wages might predict the rate at which persons leave an occupation. 

We'll first need to create an additional variable to calculate the occupational turnover rate, which we'll use as our outcome variable.

Then we'll use the `lm` function provided in base R.  We'll store the regression model as an R object, so we can work with it.  We provide a description of the model in the format `outcome_variable ~ predictor1 (+ predictor2 ...)`.  We provide an optional parameter `na.action = na.exclude` to direct how missing values should be handled.

```{R}
projections_data <- projections_data |>
    mutate(
        turnover_rate = (Exits + Transfers) / Current_jobs
        )

projections_model <- lm(turnover_rate ~ annual_wage, 
                            data = projections_data,
                            na.action = na.exclude)

summary(projections_model)
```

You can see that annual wages does appear to be a strong predictor of occupational turnover rate, since its coefficient is statistically significant and the model explains a considerable proportion of the variance.

Keen-eyed readers will note that wages may not be sufficiently normal to use as a variable in linear regression and likely needs a data transformation.  Variables with quantity often need a log transform to be treated as sufficiently normal.  We can make a quick adjustment to our code for this, without even needing a new variable:

```{R}
projections_model <- lm(turnover_rate ~ log(annual_wage), 
                            data = projections_data,
                            na.action = na.exclude)

summary(projections_model)
```

This correction seems to have improved our model considerably, as the model now explains even more of the variance in occupational turnover rate.

The residuals may be of interest,^[So that we can use them in @sec-reports!] so let's pull them back into our projections_data:

```{R}
projections_data <- projections_data |>
    mutate(residuals = residuals(projections_model))

glimpse(projections_data)
```

## Data visualizations

R can be used to create all kinds of graphs, utilizing the `ggplot2` package from `tidyverse`.  The `ggplot2` package is based on (and named after) a book, The Grammar of Graphics [@wilkinson2012grammar].  This is arguably one of the most complex packages, so you'll want to have the [site](https://ggplot2.tidyverse.org/) and [cheat sheet](https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf) available for review while you're learning it.

In this section we'll work with the IPEDS data we cleaned in @sec-data.

{{< include cleanipedsdata.qmd >}}

### Visualization #1

For our first visualization, we'll keep the data simple.  We just want to create a bar chart summarizing the number of postsecondary institutions in Ohio by sector.

We first need to aggregate the data a bit.  We'll use `summarize()` and `group_by()`.  These functions act like steps in an Excel pivot table, with `group_by()` selecting which variables should be grouped in rows, and `summarize()` taking aggregations like `mean()` to calculate values.

```{R}
sector_counts <- combined |>
    group_by(SECTOR) |>
    summarize(
        unique_inst = n_distinct(UNITID.x)
    )
```

A plot in `ggplot2` includes three basic parts: the dataset you're using, the definition of the coordinate system and aesthetics, and the geometry (shapes) that you want to display.  We use `+` to add on the geometry layer (and any further optional layers).

```{R}
sector_counts |> # start with the summarized data
    # use an x,y coordinate system with SECTOR and unique_inst
    ggplot(aes(x = SECTOR, y = unique_inst)) +
    # apply bar shapes by using values in the data
    geom_col()
```

This isn't very pretty, but we can make some adjustments.  First, we should consider the order of our chart, which we can rearrange using `reorder()` and providing a field and order (`-` for descending):

```{R}
sector_counts |> # start with the summarized data
    # use an x,y coordinate system with SECTOR and unique_inst
    ggplot(aes(x = reorder(SECTOR, -unique_inst), y = unique_inst)) +
    # apply bar shapes by using values in the data
    geom_col()
```

Now let's start to label it.  We would like both data labels and axes labels, as well as a title:

```{R}
sector_counts |> # start with the summarized data
    # use an x,y coordinate system with SECTOR and unique_inst
    ggplot(aes(x = reorder(SECTOR, -unique_inst), y = unique_inst)) +
    # apply bar shapes by using values in the data
    geom_col() +
    # add data labels
    geom_text(aes(label = unique_inst), vjust = -0.5, size = 3) +
    # label axes and provide title
    labs(
        title = "Distribution of Ohio Institutions by Sector",
        x = "Sector",
        y = "Number of institutions"
    )
```

Now let's pretty it up.  We need to adjust the x axis labels, and change up the colors.  We can change the bar color with an optional `fill` parameter to `geom_col()`, and adjust the labels and background with a `theme` layer:

```{R}
sector_counts |> # start with the summarized data
    # use an x,y coordinate system with SECTOR and unique_inst
    ggplot(aes(x = reorder(SECTOR, -unique_inst), y = unique_inst)) +
    # apply bar shapes by using values in the data, use blue color
    geom_col(fill = "blue") +
    # add data labels
    geom_text(aes(label = unique_inst), vjust = -0.5, size = 3) +
    # label axes and provide title
    labs(
        title = "Distribution of Ohio Institutions by Sector",
        x = "Sector",
        y = "Number of institutions"
    ) +
    theme(
        axis.text.x = element_text(angle = 40, hjust = 1, size = 6),
        panel.background = element_blank()
    )
```

That's much nicer!  Let's make a few more adjustments.  We can specify a particular shade of blue with an exact hex code.  [Columbus State Community College](https://www.cscc.edu/employee/communications/marketing/branding.shtml) uses a blue of R:0 G:114 B:152, which is a hex code of `#007298`.  Then we'll add a caption (in the labels layer `labs()`), a box around the chart (a new `geom_rect()` layer), and add additional `theme()` options:

```{R}
sector_counts |> # start with the summarized data
    # use an x,y coordinate system with SECTOR and unique_inst
    ggplot(aes(x = reorder(SECTOR, -unique_inst), y = unique_inst)) +
    # apply bar shapes by using values in the data, use blue color
    geom_col(fill = "#007298", color = "black") +
    # add data labels
    geom_text(aes(label = unique_inst), vjust = -0.5, size = 3) +
    # label axes and provide title
    labs(
        title = "Distribution of Ohio Institutions by Sector",
        x = "Sector",
        y = "Number of institutions",
        # new caption
        caption = "Data Source: IPEDS Data Center"
    ) +
    theme(
        axis.text.x = element_text(angle = 40, hjust = 1, size = 6),
        panel.background = element_blank(),
        axis.title.x = element_text(margin = margin(t = 10), color = "black"),
        axis.title.y = element_text(margin = margin(t = 10), color = "black"),
        axis.text = element_text(color = "black")
    ) +
    # add box around chart
    geom_rect(
        aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf),
        color = "black",
        fill = NA,
        alpha = 0
        )
```

### Visualization #2

Next, we'll illustrate how to create a different style of chart that may be helpful with more complex data.  We'll continue to use the IPEDS dataset, but now we'll work with the completions data.

First we'll again want to summarize the data.  Let's get the sum of awards (`CTOTALT`) by `CIPCODE` within `SECTOR`, focusing only on the public sector.  We also need to make a slight adjustment to CIPCODE since there is a total code (99).

```{R}
#| warning: false
sector_awards <- combined |>
    filter(
        CIPCODE != 99, # remove special code for totals at award level
        str_sub(SECTOR, 1, 6) == "Public"  # focus only on public sector for now
        ) |>
    group_by(SECTOR, CIPCODE) |>
    summarize(TotalAwards = sum(CTOTALT))
```

Since there are a lot of CIP codes, we likely want to take a look at the top CIP codes by number of awards.  We'll use `slice_max()` to pick the top 5 CIP codes:

```{R}
top_awards <- sector_awards |>
    slice_max(order_by = TotalAwards, n = 5)

top_awards
```

Now we'll create a more complex visual, still using the bar chart.  We'll work off of the `top_awards` we just created.  We'll start with the bar chart mostly as before in Visualization #1, with the exception of allowing the bars to be colored differently by sector.

Next we'll add data labels to the bars, much like in Visualization #1.

Then we'll add a new feature: `facet`.  By adding a `facet_wrap` layer, we'll actually create a multiple plot arrangement.  Since total numbers of awards may vary considerably between the sectors, we'll let the y-axes be independent.

Following, we'll label the plot with a title and axes labels.

We'll use a `theme` layer again to modify the look, including applying a `classic` theme this time.  We'll also specify a custom color palette.

```{R}
top_awards |>
    ggplot(aes(x = TotalAwards, y = reorder(CIPCODE, -TotalAwards))) +
    # apply bar geometry but allow colors to vary by sector
    geom_col(aes(fill = SECTOR)) +
    # add data labels
    geom_text(aes(label = TotalAwards), hjust = -0.25, size = 3, color = "black") +
    # add facet layer
    facet_wrap(
        ~SECTOR,
        scales = "free_y"
    ) +
    # axes labels and title
    labs(
        title = "Top 5 CIP codes by awards conferred, public institutions",
        x = "Awards conferred",
        y = "CIP code",
        caption = "Data Source: IPEDS Data Center"
    ) +
    # apply theming
    theme_classic() +
    theme(
        axis.text = element_text(size = 8, color = "black"),
        legend.position = "none"
    ) +
    # apply color palette
    scale_fill_manual(values = c("#003E52", "#99DAEA", "#646569"))
```

Now you have a taste of the complexity that you can add with `ggplot2`!

## Exercises {.unnumbered}

### Exercise 1

Describe how you would quickly examine and summarize a dataset.

```{R}
#| code-fold: true
# examine a dataset: glimpse()
# summary descriptive statistics: summary()
```

### Exercise 2

Open the [`ggplot2` cheat sheet](https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf).  Take a look in particular at the "Geoms" section.  What types of graphs do you think will be most useful in your work?


## Extra: logistic regression {.unnumbered}

In institutional research working with student data, we often create binary variables like retention, persistence, transfer, and graduation.  To work with binary outcome variables like these, we need to use methods designed for working with binary outcome variables, like logistic regression.

Luckily, R provides a package, `glm`, for generalized linear models like logistic regression.  `glm` includes a parameter `family`, for which providing `family = "binomial"` will provide for logistic regression.^[By default, this uses the logit link function, but using `family = binomial(link = "probit")` will change it to probit regression, etc.]

## Extra: propensity score matching {.unnumbered}

Another increasingly important technique for the IR toolbox is propensity score matching, which can be used to create comparison groups for impact evaluation, taking into account factors that may be associated with the likelihood of participating in a program.  The `MatchIt` package provides the functions to carry out this approach, as well as vignettes that provide a good summary [@ho_matchit_2023].